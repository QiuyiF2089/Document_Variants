{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: pymupdf in /opt/anaconda3/envs/deeplearning/lib/python3.11/site-packages (1.24.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def pdf_to_text_and_images(pdf_path, output_dir, poppler_path=None):\n",
    "    \"\"\"\n",
    "    从 PDF 提取文本和图像，保存为 JSON 文件和 PNG 文件。\n",
    "    \n",
    "    :param pdf_path: 输入 PDF 文件路径\n",
    "    :param output_dir: 输出文件夹路径\n",
    "    :param poppler_path: Poppler 的安装路径\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 动态生成文件夹名和 JSON 文件名\n",
    "    base_name = os.path.basename(pdf_path).rsplit(\".\", 1)[0]\n",
    "    images_folder = os.path.join(output_dir, base_name)  # 创建以 PDF 名称为基础的图像子文件夹\n",
    "    if not os.path.exists(images_folder):\n",
    "        os.makedirs(images_folder)\n",
    "    json_output_path = os.path.join(output_dir, f\"{base_name}.json\")\n",
    "    \n",
    "    # 将 PDF 转换为图像\n",
    "    images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "    \n",
    "    # 初始化 JSON 数据结构\n",
    "    pdf_data = {\"pages\": []}\n",
    "    \n",
    "    # 处理每一页\n",
    "    for i, image in enumerate(images):\n",
    "        # 将当前页保存为 PNG 文件（存储到 images_folder 中）\n",
    "        image_path = os.path.join(images_folder, f\"{base_name}_page_{i + 1}.png\")\n",
    "        image.save(image_path, \"PNG\")\n",
    "        \n",
    "        # 使用 Tesseract OCR 提取文本\n",
    "        text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "        \n",
    "        # 添加到 JSON 数据结构\n",
    "        pdf_data[\"pages\"].append({\n",
    "            \"page_number\": i + 1,\n",
    "            \"text\": text,\n",
    "            \"image_path\": image_path\n",
    "        })\n",
    "    \n",
    "    # 将 JSON 数据写入文件\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(pdf_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"JSON 数据已保存到: {json_output_path}\")\n",
    "    print(f\"图像已保存到文件夹: {images_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_from_json_file(original_json_path, word_to_remove):\n",
    "    \"\"\"\n",
    "    从 JSON 文件中删除指定单词，并生成一个新 JSON 文件，文件名为 `原文件名-单词.json`。\n",
    "    \n",
    "    :param original_json_path: 原始 JSON 文件路径\n",
    "    :param word_to_remove: 要删除的单词\n",
    "    \"\"\"\n",
    "    # 读取原始文件名和路径\n",
    "    base_name = os.path.basename(original_json_path).rsplit(\".\", 1)[0]\n",
    "    output_dir = os.path.dirname(original_json_path)\n",
    "    new_file_name = f\"{base_name}-{word_to_remove}.json\"\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    # 读取原始 JSON 数据\n",
    "    with open(original_json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    # 遍历每一页，删除指定单词\n",
    "    for page in json_data[\"pages\"]:\n",
    "        words = page[\"text\"].split()\n",
    "        filtered_words = [word for word in words if word.lower() != word_to_remove.lower()]\n",
    "        page[\"text\"] = \" \".join(filtered_words)\n",
    "    \n",
    "    # 将新 JSON 数据写入文件\n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as new_file:\n",
    "        json.dump(json_data, new_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"新 JSON 数据已保存到: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 数据已保存到: ./output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\n",
      "图像已保存到文件夹: ./output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.pdf\"\n",
    "output_folder = \"./output\"\n",
    "pdf_to_text_and_images(pdf_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新 JSON 数据已保存到: ./output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2-financial.json\n"
     ]
    }
   ],
   "source": [
    "json_path = \"./output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\"\n",
    "word_to_remove = \"financial\"\n",
    "\n",
    "remove_word_from_json_file(json_path, word_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arabic_to_roman(num):\n",
    "    \"\"\"\n",
    "    将阿拉伯数字转换为罗马数字。\n",
    "    \n",
    "    :param num: 阿拉伯数字 (1-3999)\n",
    "    :return: 罗马数字字符串\n",
    "    \"\"\"\n",
    "    if not (0 < num < 4000):\n",
    "        return str(num)  # 如果数字超出范围，直接返回原数字字符串\n",
    "    \n",
    "    \n",
    "    roman_numerals = {\n",
    "        1000: \"M\", 900: \"CM\", 500: \"D\", 400: \"CD\",\n",
    "        100: \"C\", 90: \"XC\", 50: \"L\", 40: \"XL\",\n",
    "        10: \"X\", 9: \"IX\", 5: \"V\", 4: \"IV\", 1: \"I\"\n",
    "    }\n",
    "    result = \"\"\n",
    "    for value, numeral in roman_numerals.items():\n",
    "        while num >= value:\n",
    "            result += numeral\n",
    "            num -= value\n",
    "    return result\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "def replace_numbers_with_roman(json_path):\n",
    "    \"\"\"\n",
    "    将 JSON 文件中的阿拉伯数字替换为罗马数字，并保存为新文件。\n",
    "    \n",
    "    :param json_path: JSON 文件路径\n",
    "    \"\"\"\n",
    "    # 读取原始 JSON 文件\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    # 替换文本中的数字为罗马数字\n",
    "    def replace_numbers_in_text(text):\n",
    "        def convert_match_to_roman(match):\n",
    "            number = int(match.group())\n",
    "            return arabic_to_roman(number)\n",
    "        \n",
    "        # 使用正则匹配所有数字\n",
    "        return re.sub(r'\\b\\d+\\b', convert_match_to_roman, text)\n",
    "    \n",
    "    # 更新 JSON 数据中的文本\n",
    "    updated_data = {\"pages\": []}\n",
    "    for page in data[\"pages\"]:\n",
    "        original_text = page[\"text\"]\n",
    "        updated_text = replace_numbers_in_text(original_text)\n",
    "        updated_data[\"pages\"].append({\n",
    "            \"page_number\": page[\"page_number\"],\n",
    "            \"text\": updated_text,\n",
    "            \"image_path\": page[\"image_path\"]\n",
    "        })\n",
    "    \n",
    "    # 保存为新 JSON 文件\n",
    "    base_name = os.path.basename(json_path).rsplit(\".\", 1)[0]\n",
    "    output_dir = os.path.dirname(json_path)\n",
    "    new_file_name = f\"{base_name}-roman.json\"\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as new_json_file:\n",
    "        json.dump(updated_data, new_json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"已将数字替换为罗马数字，新文件保存到: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将数字替换为罗马数字，新文件保存到: output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2-roman.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\"\n",
    "replace_numbers_with_roman(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "def remove_random_punctuation_from_text(text):\n",
    "    \"\"\"\n",
    "    从文本中随机删除一个标点符号。\n",
    "    \n",
    "    :param text: 输入的文本字符串\n",
    "    :return: 删除一个标点符号后的新文本\n",
    "    \"\"\"\n",
    "    # 定义标点符号列表\n",
    "    punctuation_marks = set(string.punctuation)\n",
    "    \n",
    "    # 找到文本中的所有标点符号及其索引\n",
    "    punctuation_indices = [(i, char) for i, char in enumerate(text) if char in punctuation_marks]\n",
    "    \n",
    "    # 如果没有标点符号，直接返回原文本\n",
    "    if not punctuation_indices:\n",
    "        return text\n",
    "    \n",
    "    # 随机选择一个标点符号的位置\n",
    "    index_to_remove, _ = random.choice(punctuation_indices)\n",
    "    \n",
    "    # 删除选中的标点符号\n",
    "    new_text = text[:index_to_remove] + text[index_to_remove + 1:]\n",
    "    return new_text\n",
    "\n",
    "def remove_random_punctuation_from_json(json_path):\n",
    "    \"\"\"\n",
    "    随机删除 JSON 文件中某一段文本的一个标点符号，并保存为新文件。\n",
    "    \n",
    "    :param json_path: JSON 文件路径\n",
    "    \"\"\"\n",
    "    # 读取原始 JSON 文件\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    # 随机删除标点符号\n",
    "    updated_data = {\"pages\": []}\n",
    "    for page in data[\"pages\"]:\n",
    "        original_text = page[\"text\"]\n",
    "        updated_text = remove_random_punctuation_from_text(original_text)\n",
    "        updated_data[\"pages\"].append({\n",
    "            \"page_number\": page[\"page_number\"],\n",
    "            \"text\": updated_text,\n",
    "            \"image_path\": page[\"image_path\"]\n",
    "        })\n",
    "    \n",
    "    # 保存为新 JSON 文件\n",
    "    base_name = os.path.basename(json_path).rsplit(\".\", 1)[0]\n",
    "    output_dir = os.path.dirname(json_path)\n",
    "    new_file_name = f\"{base_name}-random-punctuation-removed.json\"\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as new_json_file:\n",
    "        json.dump(updated_data, new_json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"已随机删除标点符号，新文件保存到: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已随机删除标点符号，新文件保存到: output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2-random-punctuation-removed.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\"\n",
    "remove_random_punctuation_from_json(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def change_case_in_text(text, target_word, to_upper=True):\n",
    "    \"\"\"\n",
    "    将文本中指定的单词变成全大写或全小写。\n",
    "    \n",
    "    :param text: 输入的文本字符串\n",
    "    :param target_word: 需要改变大小写的目标单词\n",
    "    :param to_upper: 如果为 True，将变成全大写；否则变成全小写\n",
    "    :return: 修改后的新文本\n",
    "    \"\"\"\n",
    "    # 根据用户需求改变大小写\n",
    "    if to_upper:\n",
    "        new_word = target_word.upper()\n",
    "    else:\n",
    "        new_word = target_word.lower()\n",
    "    \n",
    "    # 替换所有匹配的单词（不区分大小写）\n",
    "    words = text.split()\n",
    "    updated_words = [new_word if word.lower() == target_word.lower() else word for word in words]\n",
    "    \n",
    "    return \" \".join(updated_words)\n",
    "\n",
    "def change_case_in_json(json_path, target_word, to_upper=True):\n",
    "    \"\"\"\n",
    "    将 JSON 文件中指定的单词变成全大写或全小写，并保存为新文件。\n",
    "    \n",
    "    :param json_path: JSON 文件路径\n",
    "    :param target_word: 需要改变大小写的目标单词\n",
    "    :param to_upper: 如果为 True，将变成全大写；否则变成全小写\n",
    "    \"\"\"\n",
    "    # 读取原始 JSON 文件\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    # 更新 JSON 数据中的文本\n",
    "    updated_data = {\"pages\": []}\n",
    "    for page in data[\"pages\"]:\n",
    "        original_text = page[\"text\"]\n",
    "        updated_text = change_case_in_text(original_text, target_word, to_upper)\n",
    "        updated_data[\"pages\"].append({\n",
    "            \"page_number\": page[\"page_number\"],\n",
    "            \"text\": updated_text,\n",
    "            \"image_path\": page[\"image_path\"]\n",
    "        })\n",
    "    \n",
    "    # 保存为新 JSON 文件\n",
    "    base_name = os.path.basename(json_path).rsplit(\".\", 1)[0]\n",
    "    output_dir = os.path.dirname(json_path)\n",
    "    new_file_name = f\"{base_name}-{target_word}-{'upper' if to_upper else 'lower'}.json\"\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as new_json_file:\n",
    "        json.dump(updated_data, new_json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"已将单词 '{target_word}' 变为 {'全大写' if to_upper else '全小写'}，新文件保存到: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将单词 'NBA' 变为 全小写，新文件保存到: output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2-NBA-lower.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\"\n",
    "target_word = \"NBA\"  # 需要改变大小写的单词\n",
    "to_upper = False  # 如果为 True，变成全大写；如果为 False，变成全小写\n",
    "\n",
    "change_case_in_json(json_file_path, target_word, to_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def shuffle_word(word):\n",
    "    \"\"\"\n",
    "    将单词的字符顺序打乱。\n",
    "    \n",
    "    :param word: 输入单词\n",
    "    :return: 字符顺序打乱后的单词\n",
    "    \"\"\"\n",
    "    word_list = list(word)\n",
    "    random.shuffle(word_list)\n",
    "    return ''.join(word_list)\n",
    "\n",
    "def shuffle_word_in_text(text, target_word):\n",
    "    \"\"\"\n",
    "    将文本中指定的单词字符顺序打乱。\n",
    "    \n",
    "    :param text: 输入文本\n",
    "    :param target_word: 要打乱字符顺序的目标单词\n",
    "    :return: 替换后的文本\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    updated_words = [\n",
    "        shuffle_word(word) if word.lower() == target_word.lower() else word\n",
    "        for word in words\n",
    "    ]\n",
    "    return \" \".join(updated_words)\n",
    "\n",
    "def shuffle_word_in_json(json_path, target_word):\n",
    "    \"\"\"\n",
    "    将 JSON 文件中指定单词的字符顺序打乱，并保存为新文件。\n",
    "    \n",
    "    :param json_path: JSON 文件路径\n",
    "    :param target_word: 要打乱字符顺序的目标单词\n",
    "    \"\"\"\n",
    "    # 读取原始 JSON 文件\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    # 更新 JSON 数据中的文本\n",
    "    updated_data = {\"pages\": []}\n",
    "    for page in data[\"pages\"]:\n",
    "        original_text = page[\"text\"]\n",
    "        updated_text = shuffle_word_in_text(original_text, target_word)\n",
    "        updated_data[\"pages\"].append({\n",
    "            \"page_number\": page[\"page_number\"],\n",
    "            \"text\": updated_text,\n",
    "            \"image_path\": page[\"image_path\"]\n",
    "        })\n",
    "    \n",
    "    # 保存为新 JSON 文件\n",
    "    base_name = os.path.basename(json_path).rsplit(\".\", 1)[0]\n",
    "    output_dir = os.path.dirname(json_path)\n",
    "    new_file_name = f\"{base_name}-{target_word}-shuffled.json\"\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as new_json_file:\n",
    "        json.dump(updated_data, new_json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"已将单词 '{target_word}' 字符顺序打乱，新文件保存到: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将单词 'example' 字符顺序打乱，新文件保存到: output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2-example-shuffled.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\"\n",
    "target_word = \"example\"  # 需要打乱的目标单词\n",
    "\n",
    "shuffle_word_in_json(json_file_path, target_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def remove_spaces_in_sentence(text):\n",
    "    \"\"\"\n",
    "    从文本中随机选择一句话，并将其中的单词连接在一起。\n",
    "    \n",
    "    :param text: 输入文本\n",
    "    :return: 修改后的文本\n",
    "    \"\"\"\n",
    "    # 将文本分割成句子，使用常见标点符号进行分割\n",
    "    sentences = [s.strip() for s in re.split(r'(?<=[.!?]) +', text) if s.strip()]\n",
    "    \n",
    "    # 如果没有句子，直接返回原文本\n",
    "    if not sentences:\n",
    "        return text\n",
    "    \n",
    "    # 随机选择一句话\n",
    "    index_to_modify = random.randint(0, len(sentences) - 1)\n",
    "    \n",
    "    # 删除该句子中的所有单词间的空格\n",
    "    sentences[index_to_modify] = sentences[index_to_modify].replace(\" \", \"\")\n",
    "    \n",
    "    # 重新组合成文本\n",
    "    return \" \".join(sentences)\n",
    "\n",
    "def remove_spaces_in_sentence_in_json(json_path):\n",
    "    \"\"\"\n",
    "    从 JSON 文件中随机选择一段文本的句子，并将其中的单词连接在一起。\n",
    "    \n",
    "    :param json_path: JSON 文件路径\n",
    "    \"\"\"\n",
    "    # 读取原始 JSON 文件\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    # 更新 JSON 数据中的文本\n",
    "    updated_data = {\"pages\": []}\n",
    "    for page in data[\"pages\"]:\n",
    "        original_text = page[\"text\"]\n",
    "        updated_text = remove_spaces_in_sentence(original_text)\n",
    "        updated_data[\"pages\"].append({\n",
    "            \"page_number\": page[\"page_number\"],\n",
    "            \"text\": updated_text,\n",
    "            \"image_path\": page[\"image_path\"]\n",
    "        })\n",
    "    \n",
    "    # 保存为新 JSON 文件\n",
    "    base_name = os.path.basename(json_path).rsplit(\".\", 1)[0]\n",
    "    output_dir = os.path.dirname(json_path)\n",
    "    new_file_name = f\"{base_name}-sentence-no-spaces.json\"\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    with open(new_file_path, \"w\", encoding=\"utf-8\") as new_json_file:\n",
    "        json.dump(updated_data, new_json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"已随机删除句子中单词间距，新文件保存到: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已随机删除句子中单词间距，新文件保存到: output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2-sentence-no-spaces.json\n"
     ]
    }
   ],
   "source": [
    "json_file_path = \"output/2021_NMBHOF_Financial_Statements_Parent_-_Signed_2.json\"\n",
    "\n",
    "remove_spaces_in_sentence_in_json(json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
